
---
# Source: logstash/templates/patterns-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: hasty-swan-logstash-patterns
  labels:
    app: logstash
    chart: logstash-0.6.3
    release: hasty-swan
    heritage: Tiller
data:
---
# Source: logstash/templates/pipeline-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: hasty-swan-logstash-pipeline
  labels:
    app: logstash
    chart: logstash-0.6.3
    release: hasty-swan
    heritage: Tiller
data:
  input_main: |-
    input {
      # udp {
      #   port => 1514
      #   type => syslog
      # }
      # tcp {
      #   port => 1514
      #   type => syslog
      # }
      beats {
        port => 5044
      }
      # http {
      #   port => 8080
      # }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html
      #   bootstrap_servers => "kafka-input:9092"
      #   codec => json { charset => "UTF-8" }
      #   consumer_threads => 1
      #   topics => ["source"]
      #   type => "example"
      # }
    }
  output_main: |-
    output {
      # stdout { codec => rubydebug }
      elasticsearch {
        hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
        manage_template => false
        index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
        document_type => "%{[@metadata][type]}"
      }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-kafka.html
      #   bootstrap_servers => "kafka-output:9092"
      #   codec => json { charset => "UTF-8" }
      #   compression_type => "lz4"
      #   topic_id => "destination"
      # }
    }
---
# Source: logstash/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: hasty-swan-logstash
  labels:
    app: logstash
    chart: logstash-0.6.3
    release: hasty-swan
    heritage: Tiller
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: beats
      
  selector:
    app: logstash
    release: hasty-swan
---
# Source: logstash/templates/statefulset.yaml
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: hasty-swan-logstash
  labels:
    app: logstash
    chart: logstash-0.6.3
    release: hasty-swan
    heritage: Tiller
spec:
  serviceName: hasty-swan-logstash
  replicas: 1
  selector:
    matchLabels:
      app: logstash
      release: hasty-swan
  template:
    metadata:
      labels:
        app: logstash
        release: hasty-swan
      annotations:
        checksum/patterns: 1c29cb76cc2f6ce6fe8cb880e7af3c6cf0fa7339431895d47725f11d7bb9fcac
        checksum/pipeline: bd5be07af1069ebca3cf0d62ff69aaed4580d43a276eba0021b78bfe7164be55
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      containers:

        ## logstash
        - name: logstash
          image: "docker.elastic.co/logstash/logstash-oss:6.2.2"
          imagePullPolicy: IfNotPresent
          ports:
            - name: monitor
              containerPort: 9600
              protocol: TCP
            - containerPort: 5044
              name: beats
              protocol: TCP
            
          livenessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
            
          readinessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
            
          env:
            ## Logstash monitoring API host and port env vars
            - name: HTTP_HOST
              value: "0.0.0.0"
            - name: HTTP_PORT
              value: "9600"
            ## Elasticsearch output
            - name: ELASTICSEARCH_HOST
              value: "elasticsearch-client.default.svc.cluster.local"
            - name: ELASTICSEARCH_PORT
              value: "9200"
            ## Additional env vars
            - name: CONFIG_RELOAD_AUTOMATIC
              value: "true"
            - name: PATH_CONFIG
              value: "/usr/share/logstash/pipeline"
            - name: PATH_DATA
              value: "/usr/share/logstash/data"
            - name: QUEUE_CHECKPOINT_WRITES
              value: "1"
            - name: QUEUE_DRAIN
              value: "true"
            - name: QUEUE_MAX_BYTES
              value: "1gb"
            - name: QUEUE_TYPE
              value: "persisted"
          resources:
            {}
            
          volumeMounts:
            - mountPath: /usr/share/logstash/data
              name: data
            - mountPath: /usr/share/logstash/patterns
              name: patterns
            - mountPath: /usr/share/logstash/pipeline
              name: pipeline
            
      volumes:
        - name: patterns
          configMap:
            name: hasty-swan-logstash-patterns
        - name: pipeline
          configMap:
            name: hasty-swan-logstash-pipeline

  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "2Gi"
---
# Source: logstash/templates/poddisruptionbudget.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: hasty-swan-logstash
  labels:
    app: logstash
    chart: logstash-0.6.3
    release: hasty-swan
    heritage: Tiller
spec:
  selector:
    matchLabels:
      app: logstash
      release: hasty-swan
  maxUnavailable: 1
